{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a23fa1c-05f6-4082-a055-6d095c55dc3c",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883ed7b7-f5b9-4720-bcb2-186f6e7264a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97183e26-b3fd-4a5e-ae98-728c958351f3",
   "metadata": {},
   "source": [
    "### import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230e5018-a2c1-4748-be79-222a5b1f5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"https://raw.githubusercontent.com/GauriPaithankar/uber/main/uber_rides_data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb4702-5f39-4c00-bc21-26ff5cc7e533",
   "metadata": {},
   "source": [
    "### What is the shape of given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f10a2ce-6867-4858-be81-69eb84e4c5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642e914-cb61-4398-ad8b-354ba5f61f89",
   "metadata": {},
   "source": [
    "### How many integer columns(by default) are given in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a789a28d-066e-4893-9b59-2a97da291f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 2 integer columns.\n"
     ]
    }
   ],
   "source": [
    "integer_columns = df.select_dtypes(include='int')  # Filters integer columns\n",
    "num_integer_columns = integer_columns.shape[1]    # Counts the number of columns\n",
    "\n",
    "print(f\"The dataset has {num_integer_columns} integer columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658c566-f41e-4453-bcce-3fac1fc360c2",
   "metadata": {},
   "source": [
    "### How many missing values exists in 'dropoff_longitude' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0527f4cc-6325-4b1c-961e-e7115d66eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'dropoff_longitude' column has 1 missing values.\n"
     ]
    }
   ],
   "source": [
    "missing_values = df['dropoff_longitude'].isnull().sum()\n",
    "print(f\"The 'dropoff_longitude' column has {missing_values} missing values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913f0f8-9976-4151-b1e0-19880c068359",
   "metadata": {},
   "source": [
    "### What is the data type of ' pickup_datetime' feature in your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a8c5a67-f663-40d4-a941-9bd4e4957eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ride_id            200000 non-null  int64  \n",
      " 1   fare_amount        200000 non-null  float64\n",
      " 2   pickup_datetime    200000 non-null  object \n",
      " 3   pickup_longitude   200000 non-null  float64\n",
      " 4   pickup_latitude    200000 non-null  float64\n",
      " 5   dropoff_longitude  199999 non-null  float64\n",
      " 6   dropoff_latitude   199999 non-null  float64\n",
      " 7   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()  # This gives a summary of all columns, including their data types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e3494-d99e-42f3-b6de-c9e2bd6945ca",
   "metadata": {},
   "source": [
    "### What is the average fare amount?\n",
    "Remove the null values from the dataframe to answer the following question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82150405-fdc6-4fa7-b2c1-bda84763bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average fare amount is 11.36.\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Calculate the average of the 'fare_amount' column\n",
    "average_fare = df_cleaned['fare_amount'].mean()\n",
    "\n",
    "print(f\"The average fare amount is {average_fare:.2f}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99d1f5-07a8-4b6b-aad2-cc1472eb6aa3",
   "metadata": {},
   "source": [
    "### Calculate distance between each pickup and dropoff points using Haversine formula. \n",
    "What is the median haversine distance between pickup and dropoff location according to the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d111f641-03ba-497d-b1f1-8653e0d5a012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median Haversine distance between pickup and dropoff locations is 2.12 km.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/3585977950.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['haversine_distance'] = haversine(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example DataFrame (Replace this with your actual DataFrame)\n",
    "# df = pd.read_csv('your_dataset.csv')  # Load your dataset\n",
    "\n",
    "# Define the Haversine formula function\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Remove rows with missing latitude/longitude values\n",
    "df_cleaned = df.dropna(subset=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "\n",
    "# Apply the Haversine formula to calculate distance\n",
    "df_cleaned['haversine_distance'] = haversine(\n",
    "    df_cleaned['pickup_latitude'], df_cleaned['pickup_longitude'],\n",
    "    df_cleaned['dropoff_latitude'], df_cleaned['dropoff_longitude']\n",
    ")\n",
    "\n",
    "# Calculate the median distance\n",
    "median_distance = df_cleaned['haversine_distance'].median()\n",
    "\n",
    "print(f\"The median Haversine distance between pickup and dropoff locations is {median_distance:.2f} km.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f641d-a3cf-47b6-9cad-a9ab9dbe82fd",
   "metadata": {},
   "source": [
    "### What is the maximum haversine distance between pickup and dropoff location according to the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f628575a-51d0-499d-bbfd-263f61c3fd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum Haversine distance between pickup and dropoff locations is 16409.24 km.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/3628368114.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['haversine_distance'] = haversine(\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Define the Haversine formula function\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])  # Convert to radians\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))  # Calculate the angular distance\n",
    "    return R * c  # Return the distance in kilometers\n",
    "\n",
    "# Clean the dataset by removing rows with missing latitudes and longitudes\n",
    "df_cleaned = df.dropna(subset=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "\n",
    "# Calculate the Haversine distance for each row\n",
    "df_cleaned['haversine_distance'] = haversine(\n",
    "    df_cleaned['pickup_latitude'], df_cleaned['pickup_longitude'],\n",
    "    df_cleaned['dropoff_latitude'], df_cleaned['dropoff_longitude']\n",
    ")\n",
    "\n",
    "# Find the maximum Haversine distance\n",
    "max_distance = df_cleaned['haversine_distance'].max()\n",
    "\n",
    "print(f\"The maximum Haversine distance between pickup and dropoff locations is {max_distance:.2f} km.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db6b32-83ef-4557-b41a-91e52f213163",
   "metadata": {},
   "source": [
    "### How many rides have 0.0 haversine distance between pickup and dropoff location according to the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6e58c2a-3db7-456b-ae2e-d71dea7a5a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rides with 0.0 Haversine distance is 5632.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rides with 0.0 Haversine distance\n",
    "zero_distance_rides = df_cleaned[df_cleaned['haversine_distance'] == 0.0].shape[0]\n",
    "\n",
    "print(f\"The number of rides with 0.0 Haversine distance is {zero_distance_rides}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119b386-c3a0-4cab-9e0f-9fbbc3918c0c",
   "metadata": {},
   "source": [
    "### What is the mean 'fare_amount' for rides with 0 haversine distance?\n",
    "*\n",
    "Do you sense something fishy? Try to analyze, and give your expert opinion in Jupyter Notebook.\n",
    "2 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf5bdcf3-8080-4259-afe6-6bab365eb932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean 'fare_amount' for rides with 0.0 Haversine distance is 11.59.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean 'fare_amount' for rides with 0.0 Haversine distance\n",
    "mean_fare_zero_distance = df_cleaned[df_cleaned['haversine_distance'] == 0.0]['fare_amount'].mean()\n",
    "\n",
    "print(f\"The mean 'fare_amount' for rides with 0.0 Haversine distance is {mean_fare_zero_distance:.2f}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b5013-8520-4ec0-a90c-e96c76edecdd",
   "metadata": {},
   "source": [
    "### What is the maximum 'fare_amount' for a ride?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f80ecf-5083-492c-8b07-5692e3e7325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum fare amount for a ride is 499.00.\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum 'fare_amount'\n",
    "max_fare = df_cleaned['fare_amount'].max()\n",
    "\n",
    "print(f\"The maximum fare amount for a ride is {max_fare:.2f}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc932c59-c663-49e8-8322-5c2275977283",
   "metadata": {},
   "source": [
    "### What is the haversine distance between pickup and dropoff location for the costliest ride?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c2f0d41-036a-4a40-8ad5-5bda84876011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Haversine distance for the costliest ride is 0.00 km.\n"
     ]
    }
   ],
   "source": [
    "# Find the row with the maximum fare_amount\n",
    "costliest_ride = df_cleaned.loc[df_cleaned['fare_amount'].idxmax()]\n",
    "\n",
    "# Extract pickup and dropoff coordinates for the costliest ride\n",
    "pickup_lat = costliest_ride['pickup_latitude']\n",
    "pickup_lon = costliest_ride['pickup_longitude']\n",
    "dropoff_lat = costliest_ride['dropoff_latitude']\n",
    "dropoff_lon = costliest_ride['dropoff_longitude']\n",
    "\n",
    "# Calculate the Haversine distance for the costliest ride\n",
    "costliest_haversine_distance = haversine(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon)\n",
    "\n",
    "print(f\"The Haversine distance for the costliest ride is {costliest_haversine_distance:.2f} km.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6533af-6c1d-4218-8813-7cb216abf5cf",
   "metadata": {},
   "source": [
    "### How many rides were recorded in the year 2014?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ac9c9ce-532c-45a4-91e5-37bc6b371986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rides recorded in the year 2014 is 29968.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/197966218.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/197966218.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['pickup_year'] = df_cleaned['pickup_datetime'].dt.year\n"
     ]
    }
   ],
   "source": [
    "# Convert 'pickup_datetime' to datetime if not already done\n",
    "df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
    "\n",
    "# Extract the year from 'pickup_datetime'\n",
    "df_cleaned['pickup_year'] = df_cleaned['pickup_datetime'].dt.year\n",
    "\n",
    "# Count the number of rides recorded in 2014\n",
    "rides_2014 = df_cleaned[df_cleaned['pickup_year'] == 2014].shape[0]\n",
    "\n",
    "print(f\"The number of rides recorded in the year 2014 is {rides_2014}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5574e54-34e2-4573-9739-29dee8d7b529",
   "metadata": {},
   "source": [
    "### How many rides were recorded in the first quarter of 2014?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54956e4f-2cd9-42b9-8f30-4b602f019e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rides recorded in the first quarter of 2014 is 7687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/251174882.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'pickup_datetime' is in datetime format\n",
    "df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
    "\n",
    "# Filter for rides from the first quarter of 2014 (January, February, March)\n",
    "first_quarter_2014 = df_cleaned[(df_cleaned['pickup_datetime'].dt.year == 2014) & \n",
    "                                (df_cleaned['pickup_datetime'].dt.month.isin([1, 2, 3]))]\n",
    "\n",
    "# Count the number of rides recorded in the first quarter of 2014\n",
    "rides_first_quarter_2014 = first_quarter_2014.shape[0]\n",
    "\n",
    "print(f\"The number of rides recorded in the first quarter of 2014 is {rides_first_quarter_2014}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41ee59-6ef0-4c16-bd1c-fbf2a1ca8798",
   "metadata": {},
   "source": [
    "### On which day of the week in September 2010, maximum rides were recorded ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce9224eb-292d-464d-b842-61e16c076295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The day of the week in September 2010 with the maximum number of rides was Thursday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/3838389421.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/3838389421.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  september_2010['day_of_week'] = september_2010['pickup_datetime'].dt.dayofweek\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'pickup_datetime' is in datetime format\n",
    "df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
    "\n",
    "# Filter for rides in September 2010\n",
    "september_2010 = df_cleaned[(df_cleaned['pickup_datetime'].dt.year == 2010) & \n",
    "                            (df_cleaned['pickup_datetime'].dt.month == 9)]\n",
    "\n",
    "# Extract the day of the week (0=Monday, 1=Tuesday, ..., 6=Sunday)\n",
    "september_2010['day_of_week'] = september_2010['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# Count the number of rides for each day of the week\n",
    "rides_per_day = september_2010['day_of_week'].value_counts()\n",
    "\n",
    "# Get the day with the maximum number of rides\n",
    "max_day_of_week = rides_per_day.idxmax()\n",
    "\n",
    "# Map the day index to the actual day name\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "max_day_name = day_names[max_day_of_week]\n",
    "\n",
    "print(f\"The day of the week in September 2010 with the maximum number of rides was {max_day_name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce1ab2-f4cc-49e3-b86c-c6b0f7bb00ab",
   "metadata": {},
   "source": [
    "### Apply a Machine Learning Algorithm to predict the fare amount given following input features:\n",
    "passenger_count, distance and ride_week_day.\n",
    "\n",
    "Perform a 70-30 split of data.\n",
    "\n",
    "Which algorithm gives the least adjusted R square value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af5d8e0f-432e-4c2f-8771-cba7ce3f186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/9830744.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/9830744.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['ride_week_day'] = df_cleaned['pickup_datetime'].dt.dayofweek\n",
      "/var/folders/sy/z21kjsj570s5p_jqpymmx8q40000gn/T/ipykernel_7339/9830744.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['distance'] = haversine(df_cleaned['pickup_latitude'], df_cleaned['pickup_longitude'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Adjusted R^2: 0.0004\n",
      "Decision Tree Regressor Adjusted R^2: 0.4718\n",
      "Random Forest Regressor Adjusted R^2: 0.6273\n",
      "KNN Regressor Adjusted R^2: 0.6329\n",
      "The algorithm with the least Adjusted R^2 value is Linear Regression.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Haversine formula to calculate distance (in kilometers)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])  # Convert to radians\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))  # Calculate the angular distance\n",
    "    return R * c  # Return the distance in kilometers\n",
    "\n",
    "# Prepare the data\n",
    "df_cleaned['pickup_datetime'] = pd.to_datetime(df_cleaned['pickup_datetime'])\n",
    "\n",
    "# Extract day of the week\n",
    "df_cleaned['ride_week_day'] = df_cleaned['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# Calculate the distance using Haversine formula\n",
    "df_cleaned['distance'] = haversine(df_cleaned['pickup_latitude'], df_cleaned['pickup_longitude'],\n",
    "                                    df_cleaned['dropoff_latitude'], df_cleaned['dropoff_longitude'])\n",
    "\n",
    "# Select relevant features and target variable\n",
    "X = df_cleaned[['passenger_count', 'distance', 'ride_week_day']]\n",
    "y = df_cleaned['fare_amount']\n",
    "\n",
    "# Split the data into training and testing sets (70-30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"KNN Regressor\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Function to calculate Adjusted R^2\n",
    "def adjusted_r2(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    n = len(y_test)\n",
    "    p = X_test.shape[1]\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    return adj_r2\n",
    "\n",
    "# Evaluate models and compare Adjusted R^2 values\n",
    "adjusted_r2_values = {}\n",
    "for model_name, model in models.items():\n",
    "    adj_r2 = adjusted_r2(model, X_train, X_test, y_train, y_test)\n",
    "    adjusted_r2_values[model_name] = adj_r2\n",
    "    print(f\"{model_name} Adjusted R^2: {adj_r2:.4f}\")\n",
    "\n",
    "# Find the model with the least Adjusted R^2\n",
    "least_adj_r2_model = min(adjusted_r2_values, key=adjusted_r2_values.get)\n",
    "print(f\"The algorithm with the least Adjusted R^2 value is {least_adj_r2_model}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74bd2c-7014-4eea-9fdd-dff5c3d7a610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
